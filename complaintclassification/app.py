import streamlit as st
import openai
import pandas as pd
from typing import List
from pinecone import Pinecone, ServerlessSpec

# Initialize session state for tracking initialization
if 'initialized' not in st.session_state:
    st.session_state.initialized = False

# ðŸ”¹ Load API keys from Streamlit secrets
try:
    openai.api_key = st.secrets["OPENAI_API_KEY"]
    pc = Pinecone(api_key=st.secrets["PINECONE_API_KEY"])
except Exception as e:
    st.error(f"Error loading API keys. Please check your .streamlit/secrets.toml file: {str(e)}")
    st.stop()

index_name = "debt-complaints-index"

# Initialize Pinecone connection
@st.cache_resource
def initialize_pinecone():
    try:
        # Get the index
        return pc.Index(index_name)
    except Exception as e:
        st.error(f"Error connecting to Pinecone: {str(e)}")
        st.stop()

# Generate embeddings with OpenAI
@st.cache_data
def get_embedding(text: str) -> List[float]:
    try:
        response = openai.Embedding.create(input=text, model="text-embedding-ada-002")
        return response["data"][0]["embedding"]
    except Exception as e:
        st.error(f"Error generating embedding: {str(e)}")
        st.stop()

# Main application flow
st.title("ðŸ“Œ Consumer Debt Complaint Analyzer")
st.write("Enter a consumer complaint to find similar complaints from our database.")

# Initialize Pinecone connection
index = initialize_pinecone()

# User interface
user_input = st.text_area("Enter Complaint Narrative:", height=150)

if st.button("Find Similar Complaints"):
    if not user_input.strip():
        st.error("Please enter a complaint narrative.")
    else:
        try:
            with st.spinner("Analyzing your complaint..."):
                # Generate embedding for user input
                embedding = get_embedding(user_input)
                
                # Query Pinecone for similar complaints
                response = index.query(
                    vector=embedding,
                    top_k=5,  # Increased to 5 similar complaints
                    include_metadata=True
                )
                
                if not response["matches"]:
                    st.info("No similar complaints found in the database.")
                else:
                    st.subheader("ðŸ”— Most Similar Complaints:")
                    for i, match in enumerate(response["matches"], 1):
                        similarity_score = match["score"] * 100  # Convert to percentage
                        st.markdown(
                            f"""
                            **Similar Complaint #{i}**
                            - **Issue Type:** {match['metadata'].get('Issue', 'Unknown')}
                            - **Similarity Score:** {similarity_score:.1f}%
                            ---
                            """
                        )
                        
        except Exception as e:
            st.error(f"Error processing your request: {str(e)}")

